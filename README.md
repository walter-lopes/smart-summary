# ðŸ§  Smart Summary App

A full-stack application that allows users to paste a block of text (e.g. article, email, meeting notes) and receive a summary generated by OpenAI's LLM.

---

## ðŸ§± Tech Stack

- **Frontend:** Next.js (React)
- **Backend:** FastAPI (Python)
- **LLM Integration:** OpenAI API
- **Containerization:** Docker + Docker Compose

---

## ðŸš€ Features

- Paste long-form text and get a summary
- Streamed response from FastAPI (Server-Sent Events)
- Clean and responsive UI
- Environment variable support via `.env`
- Easy local development with `make` and `docker-compose`

---

## ðŸ§ª Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/walter-lopes/smart-summary.git
cd smart-summary-app

cd backend
make install-dev     # Installs dependencies via Pipenv
make run          # Starts FastAPI with Uvicorn


cd frontend
npm install       # Installs Node.js dependencies
npm run dev       # Starts development server on http://localhost:3000

```

## ðŸ’¡ Ideas for Future Improvements

- **Refactor backend service** into separate classes or modules for better abstraction, e.g., a `SummaryService` class handling OpenAI interactions. This allows easier extension and testing.

- **Parameterize the backend API URL** in the frontend instead of hardcoding it:

  ```js
  // Example improvement for frontend API call
  const API_URL = process.env.NEXT_PUBLIC_API_URL || "http://localhost:8000";

  const handleSubmit = async () => {
    setLoading(true);
    setSummary("");

    const response = await fetch(`${API_URL}/summary/stream`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ text: input }),
    });

    // handle response ...
  };

